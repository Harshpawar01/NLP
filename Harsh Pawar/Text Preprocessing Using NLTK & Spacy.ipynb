{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPgt8SBzzgw1qPQNlXPONia"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["quesion no 1"],"metadata":{"id":"0zzXQ9ZllMs7"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3TJrPapETJ2F","executionInfo":{"status":"ok","timestamp":1730956167493,"user_tz":-330,"elapsed":1777,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"ad51877b-040e-41dc-8074-632cd49c9588"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["['Natural', 'Language', 'Processing', 'with', 'Python', 'is', 'fun', '.']\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","\n","nltk.download('punkt')\n","\n","sentence = \"Natural Language Processing with Python is fun.\"\n","\n","tokens = word_tokenize(sentence)\n","print(tokens)\n"]},{"cell_type":"markdown","source":["quesion no 2"],"metadata":{"id":"MDBXCIhslWY-"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","import string\n","\n","sentence = \"Hello there! How's the weather today?\"\n","\n","tokens = word_tokenize(sentence)\n","\n","tokens_without_punctuation = [word for word in tokens if word not in string.punctuation]\n","\n","print(tokens_without_punctuation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yEAiK7BWTT-i","executionInfo":{"status":"ok","timestamp":1730956172284,"user_tz":-330,"elapsed":434,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"1d359dba-f48b-4bc4-85ad-395aa4b785a0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hello', 'there', 'How', \"'s\", 'the', 'weather', 'today']\n"]}]},{"cell_type":"markdown","source":["quesion no 3"],"metadata":{"id":"a2x2ERcYlZCz"}},{"cell_type":"code","source":["nltk.download('stopwords')\n","\n","sentence = \"This is a simple sentence for stopword removal.\"\n","\n","tokens = word_tokenize(sentence)\n","\n","stop_words = set(stopwords.words('english'))\n","\n","tokens_without_stopwords = [word for word in tokens if word.lower() not in stop_words]\n","\n","print(tokens_without_stopwords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"usj2Zs4xULjc","executionInfo":{"status":"ok","timestamp":1730956176807,"user_tz":-330,"elapsed":925,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"98ee7db4-059a-4f78-efa9-6db00a0402d9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['simple', 'sentence', 'stopword', 'removal', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"markdown","source":["quesion no 4"],"metadata":{"id":"BRvpzzsVlbli"}},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","\n","stemmer = PorterStemmer()\n","\n","sentence = \"The striped bats are hanging on their feet for best.\"\n","\n","tokens = word_tokenize(sentence)\n","\n","stemmed_words = [stemmer.stem(word) for word in tokens]\n","\n","print(stemmed_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTh469sYUieC","executionInfo":{"status":"ok","timestamp":1730956179565,"user_tz":-330,"elapsed":10,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"c0f8e4ec-b1cd-45d9-dc60-79d36c0ff789"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'stripe', 'bat', 'are', 'hang', 'on', 'their', 'feet', 'for', 'best', '.']\n"]}]},{"cell_type":"markdown","source":["quesion no 5"],"metadata":{"id":"lku21shcleqp"}},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","\n","lemmatizer = WordNetLemmatizer()\n","\n","sentence = \"The geese are flying south for the winter.\"\n","\n","tokens = word_tokenize(sentence)\n","\n","lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n","\n","print(lemmatized_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uCrZqSGtUy7F","executionInfo":{"status":"ok","timestamp":1730956185265,"user_tz":-330,"elapsed":2190,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"138712c6-0f45-428f-83b4-7a7b3903ffb2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["['The', 'goose', 'are', 'flying', 'south', 'for', 'the', 'winter', '.']\n"]}]},{"cell_type":"markdown","source":["quesion no 6"],"metadata":{"id":"z2qaRKPgliKA"}},{"cell_type":"code","source":["import string\n","\n","sentence = \"Hello, World! NLP with Python.\"\n","\n","sentence = sentence.lower()\n","\n","sentence_without_punctuation = ''.join([char for char in sentence if char not in string.punctuation])\n","\n","print(sentence_without_punctuation)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIOLIBnPVUgj","executionInfo":{"status":"ok","timestamp":1730956189467,"user_tz":-330,"elapsed":435,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"8d8a68e7-32ba-4946-aa7b-46559dc5f085"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["hello world nlp with python\n"]}]},{"cell_type":"markdown","source":["quesion no 7"],"metadata":{"id":"nKDYDcVHlmSK"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import sent_tokenize\n","\n","paragraph = \"Hello World. This is NLTK. Let's explore NLP!\"\n","\n","sentences = sent_tokenize(paragraph)\n","\n","print(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wu8GflOeWI_f","executionInfo":{"status":"ok","timestamp":1730956240645,"user_tz":-330,"elapsed":413,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"547f569a-38d5-4055-887d-f1a81fe1976a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hello World.', 'This is NLTK.', \"Let's explore NLP!\"]\n"]}]},{"cell_type":"markdown","source":["quesion no 8"],"metadata":{"id":"cdq9hQR6lxDZ"}},{"cell_type":"code","source":["from nltk.stem import LancasterStemmer\n","\n","nltk.download('punkt')\n","\n","stemmer = LancasterStemmer()\n","\n","sentence = \"Loving the experience of learning NLTK\"\n","\n","tokens = word_tokenize(sentence)\n","\n","stemmed_words = [stemmer.stem(word) for word in tokens]\n","\n","print(stemmed_words)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PS0_CkItWx-R","executionInfo":{"status":"ok","timestamp":1730956246549,"user_tz":-330,"elapsed":429,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"c3f6541f-db39-4e47-8414-c782f88ca493"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['lov', 'the', 'expery', 'of', 'learn', 'nltk']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["quesion no 9"],"metadata":{"id":"PVLZIgGYl014"}},{"cell_type":"code","source":["nltk.download('stopwords')\n","\n","sentence = \"This is a test sentence, with stopwords and punctuation!\"\n","\n","tokens = word_tokenize(sentence)\n","\n","stop_words = set(stopwords.words('english'))\n","\n","filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word not in string.punctuation]\n","\n","print(filtered_tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycDExZrVaWDf","executionInfo":{"status":"ok","timestamp":1730956249417,"user_tz":-330,"elapsed":421,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"f04fd76b-cfd8-4151-e816-3eab60f966df"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["['test', 'sentence', 'stopwords', 'punctuation']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["quesion no 10"],"metadata":{"id":"Lib8_nvhl3vO"}},{"cell_type":"code","source":["import nltk\n","nltk.download('averaged_perceptron_tagger')\n","\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag\n","\n","lemmatizer = WordNetLemmatizer()\n","\n","sentence = \"The striped bats are hanging on their feet.\"\n","\n","tokens = word_tokenize(sentence)\n","\n","pos_tags = pos_tag(tokens)\n","\n","def get_wordnet_pos(treebank_tag):\n","    if treebank_tag.startswith('J'):\n","        return 'a'\n","    elif treebank_tag.startswith('V'):\n","        return 'v'\n","    elif treebank_tag.startswith('N'):\n","        return 'n'\n","    elif treebank_tag.startswith('R'):\n","        return 'r'\n","    else:\n","        return None\n","\n","lemmatized_words = [\n","    lemmatizer.lemmatize(word, get_wordnet_pos(pos) or 'n')\n","    for word, pos in pos_tags\n","]\n","\n","print(lemmatized_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MmxgQz20Cb5f","executionInfo":{"status":"ok","timestamp":1730956462035,"user_tz":-330,"elapsed":13,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"640603e6-39a9-4dc0-ec8c-bde504f6429f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'striped', 'bat', 'be', 'hang', 'on', 'their', 'foot', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}]},{"cell_type":"markdown","source":["question no 11"],"metadata":{"id":"_aWXIAgIm_iI"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","import string\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","stemmer = PorterStemmer()\n","\n","sentence = \"Running through the forest, the fox is faster.\"\n","\n","tokens = word_tokenize(sentence)\n","\n","stop_words = set(stopwords.words('english'))\n","\n","processed_tokens = [\n","    stemmer.stem(word) for word in tokens\n","    if word.lower() not in stop_words and word not in string.punctuation\n","]\n","\n","print(processed_tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsjtI107msCC","executionInfo":{"status":"ok","timestamp":1730956469531,"user_tz":-330,"elapsed":428,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"b849e009-b213-4248-89ce-a9d32ff09886"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["['run', 'forest', 'fox', 'faster']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["question no 12"],"metadata":{"id":"1wC7deRGoUhH"}},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","\n","sentence = \"This is an example sentence for counting stopwords.\"\n","stop_words = set(stopwords.words('english'))\n","tokens = word_tokenize(sentence)\n","stopword_count = sum(1 for word in tokens if word.lower() in stop_words)\n","print(stopword_count)\n"],"metadata":{"id":"BqflBfsLn88v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730956478664,"user_tz":-330,"elapsed":419,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"4033c2a9-94be-4bed-d05e-f9ca609ad332"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n"]}]},{"cell_type":"markdown","source":["question no 13"],"metadata":{"id":"2KFYreq9DCal"}},{"cell_type":"code","source":["from nltk.tokenize import RegexpTokenizer\n","from nltk.stem import PorterStemmer\n","\n","sentence = \"Stemming, punctuation! Removal example.\"\n","tokenizer = RegexpTokenizer(r'\\w+')\n","stemmer = PorterStemmer()\n","tokens = tokenizer.tokenize(sentence)\n","stemmed_tokens = [stemmer.stem(word) for word in tokens]\n","print(stemmed_tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YE6Rpw7xBZQC","executionInfo":{"status":"ok","timestamp":1730956515348,"user_tz":-330,"elapsed":574,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"8b54ffbd-4e21-41cd-9f9d-919d8a735561"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["['stem', 'punctuat', 'remov', 'exampl']\n"]}]},{"cell_type":"markdown","source":["question no 14"],"metadata":{"id":"PRzfogSyDNHC"}},{"cell_type":"code","source":["import re\n","from nltk.tokenize import word_tokenize\n","\n","sentence = \"Punctuation removal with regex in NLP!\"\n","sentence = re.sub(r'[^\\w\\s]', '', sentence)\n","tokens = word_tokenize(sentence)\n","print(tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klgcRPHRDFMl","executionInfo":{"status":"ok","timestamp":1730956564073,"user_tz":-330,"elapsed":427,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"fff2b0d6-99f9-4dab-8afc-ac3c37d7ca1e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['Punctuation', 'removal', 'with', 'regex', 'in', 'NLP']\n"]}]},{"cell_type":"markdown","source":["question no 15"],"metadata":{"id":"chcCOPjzDV-I"}},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","sentence = \"The dogs are barking loudly.\"\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = WordNetLemmatizer()\n","tokens = word_tokenize(sentence)\n","filtered_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.lower() not in stop_words]\n","print(filtered_tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajSM4FtxDQ3b","executionInfo":{"status":"ok","timestamp":1730956596726,"user_tz":-330,"elapsed":17,"user":{"displayName":"Harsh Pawar","userId":"10050509502376340838"}},"outputId":"4b8553c3-cd3c-4686-dc15-5a895fa8b60a"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["['dog', 'barking', 'loudly', '.']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"00nuVnA4DY1a"},"execution_count":null,"outputs":[]}]}